# Example environment configuration file
# Copy this to .env and fill in the appropriate values

# ==================================================
# AWS
# ==================================================

# AWS account ID
# AWS_ACCOUNT_ID=<please specify a value>

# AWS region
# AWS_REGION=<please specify a value>

# ==================================================
# APPLICATION
# ==================================================

# used for CORS origin validation
# APP_URL=<please specify a value>

# use "local" for local development, or dev,preprod or prod as appropriate
# ENVIRONMENT=local

# Sentry DSN if using Sentry for telemetry
# SENTRY_DSN=<please specify a value>

# ==================================================
# AZURE OPENAI
# ==================================================

# Azure deployment for openAI
# AZURE_DEPLOYMENT=<please specify a value>

# Azure API key for openAI
# AZURE_OPENAI_API_KEY=<please specify a value>

# Azure OpenAI API version
# AZURE_OPENAI_API_VERSION=<please specify a value>

# Azure OpenAI service endpoint URL
# AZURE_OPENAI_ENDPOINT=<please specify a value>

# ==================================================
# AZURE SPEECH
# ==================================================

# Azure STT speech key for API
# AZURE_SPEECH_KEY=<please specify a value>

# Region for Azure STT
# AZURE_SPEECH_REGION=<please specify a value>

# ==================================================
# CONTENT FILTERING
# ==================================================

# Transcript must have at least this many words to be passed to complex summary stage. Note, this is disabled by default as is lower than the MIN_WORD_COUNT_FOR_SUMMARY
# MIN_WORD_COUNT_FOR_FULL_SUMMARY=199

# Transcript must have at least this many words to be passed to summary stage
# MIN_WORD_COUNT_FOR_SUMMARY=200

# ==================================================
# FEATURES
# ==================================================

# List of template names available in beta. These are currently made available via a Posthog feature flag
# BETA_TEMPLATE_NAMES='[]'

# Should the LLM check for hallucinations? Note that the results of this are currently not surfaced in the UI
# HALLUCINATION_CHECK=False

# ==================================================
# GOOGLE CLOUD
# ==================================================

# Path to Google Cloud service account credentials JSON file
# GOOGLE_APPLICATION_CREDENTIALS=<please specify a value>

# Google Cloud region/location
# GOOGLE_CLOUD_LOCATION=<please specify a value>

# Google Cloud project ID
# GOOGLE_CLOUD_PROJECT=<please specify a value>

# ==================================================
# LLM CONFIGURATION
# ==================================================

# Best LLM model name to use. Note that this should be used for higher complexity LLM tasks, like initial minute generation.
# BEST_LLM_MODEL_NAME=gemini-2.5-flash

# Best LLM provider to use. Currently 'openai' or 'gemini' are supported. Note that this should be used for higher complexity LLM tasks, like initial minute generation.
# BEST_LLM_PROVIDER=gemini

# Fast LLM model name to use. Note that this should be used for low complexity LLM tasks
# FAST_LLM_MODEL_NAME=gemini-2.5-flash-lite

# Fast LLM provider to use. Currently 'openai' or 'gemini' are supported. Note that this should be used for low complexity LLM tasks, like AI edits
# FAST_LLM_PROVIDER=gemini

# ==================================================
# LOCALSTACK
# ==================================================

# LocalStack service URL for local AWS services emulation
# LOCALSTACK_URL=http://localhost:4566

# Use LocalStack for local AWS services emulation in dev
# USE_LOCALSTACK=True

# ==================================================
# POSTHOG
# ==================================================

# PostHog API key for analytics
# POSTHOG_API_KEY=<please specify a value>

# PostHog service host URL
# POSTHOG_HOST=https://eu.i.posthog.com

# ==================================================
# QUEUE SERVICES
# ==================================================

# Azure service bus connection string
# AZURE_SB_CONNECTION_STRING=<please specify a value>

# ==================================================
# QUEUE SERVICES
# ==================================================

# deadletter queue name to use for SQS. Ignored if using Azure Service Bus.
# DEADLETTER_QUEUE_NAME=<please specify a value>

# queue name to use for SQS/Azure Service Bus queues
# QUEUE_NAME=<please specify a value>

# Queue service type to communicate with worker. Currently supported are: sqs, azure-service-bus
# QUEUE_SERVICE_NAME=sqs

# ==================================================
# RAY
# ==================================================

# Ray dashboard host IP address. Use '0.0.0.0' if running inside docker
# RAY_DASHBOARD_HOST=127.0.0.1

# ==================================================
# STORAGE
# ==================================================

# Azure Blob Storage connection string
# AZURE_BLOB_CONNECTION_STRING=<please specify a value>

# Azure container name for transcription result files. Note that Azure Batch transcription requires this.
# AZURE_TRANSCRIPTION_CONTAINER_NAME=<please specify a value>

# Azure container name for uploaded files
# AZURE_UPLOADS_CONTAINER_NAME=<please specify a value>

# S3 bucket name for data storage
# DATA_S3_BUCKET=<please specify a value>

# Storage service type to use for file uploads. Currently supported are: s3, azure-blob
# STORAGE_SERVICE_NAME=s3

# ==================================================
# TRANSCRIPTION
# ==================================================

# List of service names to use for transcription. See backend/services/transcription_services
# TRANSCRIPTION_SERVICES='["azure_stt_synchronous", "azure_stt_batch"]'

# ==================================================
# WORKER CONFIGURATION
# ==================================================

# the number of LLM workers per node
# MAX_LLM_PROCESSES=1

# the number of transcription workers per node
# MAX_TRANSCRIPTION_PROCESSES=1

# ==================================================
# DATABASE
# ==================================================

# PostgreSQL database name
# POSTGRES_DB=<please specify a value>

# PostgreSQL database host
# POSTGRES_HOST=<please specify a value>

# PostgreSQL database password
# POSTGRES_PASSWORD=<please specify a value>

# PostgreSQL database port
# POSTGRES_PORT=<please specify a value>

# PostgreSQL database user
# POSTGRES_USER=<please specify a value>
